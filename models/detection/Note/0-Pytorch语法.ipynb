{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensor.type()\n",
    "**查看张量类型：**tensor.dtype\n",
    "\n",
    "**张量类型转换：**tensor.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8731, 0.0413, 0.3893, 0.2937],\n",
      "        [0.6656, 0.4881, 0.0244, 0.1615]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((2,4))\n",
    "print(tensor)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8731, 0.0413, 0.3893, 0.2937],\n",
      "        [0.6656, 0.4881, 0.0244, 0.1615]], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "tensor = tensor.type(torch.float64)\n",
    "print(tensor)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.from_numpy()\n",
    "将numpy格式数据转换成torch.tensor\n",
    ">torch.numpy() ：将tensor转换成numpy数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# numpy的array与torch的tensor的转换\n",
    "np_data = np.arange(6).reshape((2, 3))\n",
    "np_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_data = torch.from_numpy(np_data)\n",
    "print(torch_data.shape)\n",
    "print(torch_data.size())\n",
    "torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "6\n",
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2array = torch_data.numpy() \n",
    "print(type(tensor2array))\n",
    "print(tensor2array.size)\n",
    "print(tensor2array.shape)\n",
    "tensor2array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.permute()\n",
    "改变张量轴的顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 5)\n",
    "print(type(x))\n",
    "print(x.size())\n",
    "print(x.permute(2, 0, 1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.reshape()\n",
    "调整张量形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5623,  1.5738, -0.0117, -0.4112,  0.6413],\n",
       "         [ 0.7338, -0.8092, -0.7477, -0.0963,  0.7245]],\n",
       "\n",
       "        [[-0.2340, -1.5358,  0.4822,  0.7625,  0.6357],\n",
       "         [ 0.4128, -0.5038, -0.4117, -0.8000,  0.0706]],\n",
       "\n",
       "        [[-0.8159,  0.6847,  0.1068, -1.2137,  0.3526],\n",
       "         [-0.9043,  0.3554,  0.6052, -0.8652,  1.0381]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 5)\n",
    "x.reshape(3,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(-1)  # 将x拉成一列\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [torch.arange()](https://pytorch.org/docs/stable/generated/torch.arange.html)\n",
    "生成张量序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6., 8.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 5 * 2, 2, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [torch.stack()](https://blog.csdn.net/xinjieyuan/article/details/105205326)\n",
    ">torch.stack(tensors, dim=0, out=None) → Tensor\n",
    "\n",
    "Concatenates sequence of tensors along a new dimension.  All tensors need to be of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设是时间步T1\n",
    "T1 = torch.tensor([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "# 假设是时间步T2\n",
    "T2 = torch.tensor([[10, 20, 30],\n",
    "                [40, 50, 60],\n",
    "                [70, 80, 90]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9]],\n",
       "\n",
       "        [[10, 20, 30],\n",
       "         [40, 50, 60],\n",
       "         [70, 80, 90]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((T1,T2),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack((T1,T2),dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1, 10],\n",
       "         [ 2, 20],\n",
       "         [ 3, 30]],\n",
       "\n",
       "        [[ 4, 40],\n",
       "         [ 5, 50],\n",
       "         [ 6, 60]],\n",
       "\n",
       "        [[ 7, 70],\n",
       "         [ 8, 80],\n",
       "         [ 9, 90]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((T1,T2),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack((T1,T2),dim=-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [torch.cat()](https://pytorch.org/docs/stable/generated/torch.cat.html)\n",
    ">torch.cat(tensors, dim=0, out=None) → Tensor\n",
    "\n",
    "Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3, 10, 20, 30],\n",
       "        [ 4,  5,  6, 40, 50, 60],\n",
       "        [ 7,  8,  9, 70, 80, 90]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((T1,T2),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9],\n",
       "        [10, 20, 30],\n",
       "        [40, 50, 60],\n",
       "        [70, 80, 90]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((T1,T2),dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.meshgrid()\n",
    "生成网格，可以用于生成坐标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3, 4])\n",
    "print(a)\n",
    "b = torch.tensor([4, 5, 6])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "tensor([[4, 5, 6],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "x, y = torch.meshgrid(a, b) # 相当于排列组合，生成坐标点\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f455c400110>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords_fmap2orig(feature, stride=16):  # 特征图上的grid对应于原图的位置\n",
    "    h, w = feature.shape[1:3]  \n",
    "    # h, w = 8, 8 # 为演示方便，我们使用尺寸为（4，4）的特征图\n",
    "    shifts_x = torch.arange(0, w * stride, stride, dtype=torch.float32)\n",
    "    shifts_y = torch.arange(0, h * stride, stride, dtype=torch.float32)\n",
    "    shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)\n",
    "    shift_x = torch.reshape(shift_x, [-1])\n",
    "    shift_y = torch.reshape(shift_y, [-1])\n",
    "    coords = torch.stack([shift_x, shift_y], -1) + (stride // 2)  # 中心点偏置\n",
    "    # 可视化一下，看看\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(coords[:,0], coords[:,1])\n",
    "    # plt.savefig('grid.png')\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.,  8.],\n",
       "        [24.,  8.],\n",
       "        [40.,  8.],\n",
       "        [56.,  8.],\n",
       "        [ 8., 24.],\n",
       "        [24., 24.],\n",
       "        [40., 24.],\n",
       "        [56., 24.],\n",
       "        [ 8., 40.],\n",
       "        [24., 40.],\n",
       "        [40., 40.],\n",
       "        [56., 40.],\n",
       "        [ 8., 56.],\n",
       "        [24., 56.],\n",
       "        [40., 56.],\n",
       "        [56., 56.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature = torch.rand((2,4,4))\n",
    "coords = coords_fmap2orig(feature)\n",
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [None] for Dimension\n",
    "用于增加张量维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10,dtype=torch.int32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [7],\n",
       "         [8],\n",
       "         [9]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x[None, :, None].shape)\n",
    "x[None, :, None]  # None 用于增加维度 相当于把数据都放到行维度上 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10, 20]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.from_numpy(\n",
    "    np.array([[[10, 12, 48, 60],\n",
    "               [20, 20, 40, 50]]])\n",
    "    )\n",
    "\n",
    "print(y[..., 0].shape)\n",
    "print(y.dtype)\n",
    "y[..., 0]  # 取第一列  所有gt框的xmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[10, 20]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y[..., 0][:, None, :].shape)\n",
    "y[..., 0][:, None, :]  #  增加维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-8ca8e24365b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# [1,10,1]-[1,1,2]-->[1, 10, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# None 增加维度用的\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "# [1,10,1]-[1,1,2]-->[1, 10, 2]\n",
    "off = x[None, :, None] - y[..., 0][:, None, :]   # None 增加维度用的\n",
    "off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [torch.sum（）](https://blog.csdn.net/weixin_45281949/article/details/103282148?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param)\n",
    "\n",
    "张量求和函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1,2,3,1,2],\n",
    "                   [4,5,6,3,4]],\n",
    "                  \n",
    "                  [[7,8,9,2,3],\n",
    "                   [1,1,2,1,2]],\n",
    "                  \n",
    "                  [[7,8,9,2,3],\n",
    "                   [1,1,2,1,2]]])\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/3-axis_front.png\" width=\"300\" height=\"400\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15, 18, 21,  5,  8],\n",
      "        [ 6,  7, 10,  5,  8]]) torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "b = torch.sum(a,dim=0)\n",
    "print(b, b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  7,  9,  4,  6],\n",
      "        [ 8,  9, 11,  3,  5],\n",
      "        [ 8,  9, 11,  3,  5]]) torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "c = torch.sum(a,dim=1)\n",
    "print(c,c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9, 22],\n",
      "        [29,  7],\n",
      "        [29,  7]]) torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "b = torch.sum(a,dim=2)\n",
    "print(b,b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([31, 36, 36]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "b = torch.sum(a,dim=(1,2))\n",
    "print(b,b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([31, 36, 36]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "b = torch.sum(a,dim=(2,1))\n",
    "print(b,b.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [torch.clamp()](https://blog.csdn.net/u013230189/article/details/82627375)\n",
    "截断函数，超出范围的值用指定值代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [9],\n",
      "        [4],\n",
      "        [7],\n",
      "        [6],\n",
      "        [7],\n",
      "        [1],\n",
      "        [0],\n",
      "        [5],\n",
      "        [4]])\n",
      "tensor([[3],\n",
      "        [6],\n",
      "        [4],\n",
      "        [6],\n",
      "        [6],\n",
      "        [6],\n",
      "        [3],\n",
      "        [3],\n",
      "        [5],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randint(low=0,high=10,size=(10,1))\n",
    "print(a)\n",
    "a=torch.clamp(a,3,6)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.min()/max()\n",
    "按维度选取张量中的最值，返回值和索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(24).reshape(2,3,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([[ 0,  4,  8],\n",
       "        [12, 16, 20]]),\n",
       "indices=tensor([[0, 0, 0],\n",
       "        [0, 0, 0]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.min(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([[ 0,  4,  8],\n",
       "        [12, 16, 20]]),\n",
       "indices=tensor([[0, 0, 0],\n",
       "        [0, 0, 0]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x, dim=-1)  # dim=-1 在行上看各列的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7771, 0.9971, 0.2777, 0.7096],\n",
       "        [0.9758, 0.4358, 0.1960, 0.0868],\n",
       "        [0.7660, 0.9169, 0.9004, 0.0221]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand((3,4))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.9971, 0.9758, 0.9169]),\n",
       "indices=tensor([1, 0, 1]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False,  True],\n",
       "        [ True, False, False, False],\n",
       "        [ True,  True,  True, False]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.scatter_()\n",
    ">output = torch.Tensor.scatter_(dim, index, src)\n",
    "\n",
    "[.scatter_()](https://blog.csdn.net/weixin_45798469/article/details/108311046)本身的用法有些繁琐，但是这里可以用来生成[独热编码](https://blog.csdn.net/u010630669/article/details/105425572)\n",
    "\n",
    "\n",
    "[Reference](https://medium.com/@yang6367/understand-torch-scatter-b0fd6275331c)(有空可以看看)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.tensor([1,2,1,2,0])  # [1,2,1,2,0] 5个元素对应5行，0，1，2 对应3列\n",
    "x = torch.zeros(5,3).scatter_(-1, index.unsqueeze(1), 1) \n",
    "x = x.type(torch.uint8)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0],\n",
       "         [ 1],\n",
       "         [ 2]],\n",
       "\n",
       "        [[ 3],\n",
       "         [ 4],\n",
       "         [ 5]],\n",
       "\n",
       "        [[ 6],\n",
       "         [ 7],\n",
       "         [ 8]],\n",
       "\n",
       "        [[ 9],\n",
       "         [10],\n",
       "         [11]],\n",
       "\n",
       "        [[12],\n",
       "         [13],\n",
       "         [14]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(15).reshape(5,3,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elimen/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1],\n",
       "        [ 5],\n",
       "        [ 7],\n",
       "        [11],\n",
       "        [12]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.broadcast_tensors\n",
    ">torch.broadcast_tensors(*tensors) → List of Tensors\n",
    "\n",
    "Broadcasts the given tensors according to Broadcasting semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2]])\n",
      "tensor([[0],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(3).view(1, 3)\n",
    "y = torch.arange(2).view(2, 1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[4,8,9]])\n",
    "n = torch.tensor([[2],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) \n",
      " tensor([[4, 8, 9],\n",
      "        [4, 8, 9]])\n",
      "torch.Size([2, 3]) \n",
      " tensor([[2, 2, 2],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "a, b = torch.broadcast_tensors(m, n)  ## 按照广播机制，返回两个形状相同的tensor\n",
    "\n",
    "print(a.shape,'\\n',a)\n",
    "print(b.shape,'\\n',b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [nn.parameter](https://www.jianshu.com/p/d8b77cc02410)\n",
    "可以把这个函数理解为类型转换函数，将一个不可训练的数据类型Tensor转换成可以训练的数据类型parameter，并将这个parameter绑定到这个module里面\n",
    "\n",
    "(net.parameter()中就有这个绑定的parameter，所以在参数优化的时候可以进行优化)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ScaleExp(nn.Module):\n",
    "    def __init__(self, init_value=1.0):\n",
    "        super(ScaleExp, self).__init__()\n",
    "        self.scale = nn.Parameter(torch.tensor([init_value], dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.exp(x * self.scale)  # 乘一个 可以训练的 缩放因子 scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True, '_parameters': OrderedDict([('scale', Parameter containing:\n",
       "               tensor([2.], requires_grad=True))]), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict()}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_model = ScaleExp(2)\n",
    "scale_model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('scale', Parameter containing:\n",
       "              tensor([2.], requires_grad=True))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_model._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((2,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.3891, 7.3891, 7.3891],\n",
       "        [7.3891, 7.3891, 7.3891]], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = scale_model(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.38905609893065"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(2)  # e**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [nn.ModuleList()](https://zhuanlan.zhihu.com/p/64990232)\n",
    "它是一个储存不同 module，并自动将每个 module 的 parameters 添加到网络之中的容器。但，我们需要注意的是，nn.ModuleList 并没有定义一个网络，它只是将不同的模块储存在一起，这些模块在网络之中的先后顺序`由forward函数定义`，与它们在ModuleList中的顺序没有关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): ScaleExp()\n",
       "  (1): ScaleExp()\n",
       "  (2): ScaleExp()\n",
       "  (3): ScaleExp()\n",
       "  (4): ScaleExp()\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_scale_exp = nn.ModuleList([ScaleExp(1.0) for _ in range(5)])\n",
    "self_scale_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [nn.GroupNorm()](https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html)\n",
    ">torch.nn.GroupNorm(num_groups: int, num_channels: int, eps: float = 1e-05, affine: bool = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 10, 10])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2, 6, 10, 10)\n",
    "# Separate 6 channels into 3 groups\n",
    "GN = nn.GroupNorm(3, 6) ## 类GroupNorm的实例GN\n",
    "# Separate 6 channels into 6 groups (equivalent with InstanceNorm)\n",
    "# m = nn.GroupNorm(6, 6)\n",
    "# Put all 6 channels into a single group (equivalent with LayerNorm)\n",
    "# m = nn.GroupNorm(1, 6)\n",
    "# Activating the module\n",
    "output = GN(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Normalization总结（BN/LN/IN/GN/SN）**\n",
    "\n",
    "https://blog.csdn.net/liuxiao214/article/details/81037416?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-3.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-3.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  0   1   2]\n",
      "   [  3   4   5]\n",
      "   [  6   7   8]]\n",
      "\n",
      "  [[  9  10  11]\n",
      "   [ 12  13  14]\n",
      "   [ 15  16  17]]\n",
      "\n",
      "  [[ 18  19  20]\n",
      "   [ 21  22  23]\n",
      "   [ 24  25  26]]\n",
      "\n",
      "  [[ 27  28  29]\n",
      "   [ 30  31  32]\n",
      "   [ 33  34  35]]\n",
      "\n",
      "  [[ 36  37  38]\n",
      "   [ 39  40  41]\n",
      "   [ 42  43  44]]\n",
      "\n",
      "  [[ 45  46  47]\n",
      "   [ 48  49  50]\n",
      "   [ 51  52  53]]\n",
      "\n",
      "  [[ 54  55  56]\n",
      "   [ 57  58  59]\n",
      "   [ 60  61  62]]\n",
      "\n",
      "  [[ 63  64  65]\n",
      "   [ 66  67  68]\n",
      "   [ 69  70  71]]\n",
      "\n",
      "  [[ 72  73  74]\n",
      "   [ 75  76  77]\n",
      "   [ 78  79  80]]\n",
      "\n",
      "  [[ 81  82  83]\n",
      "   [ 84  85  86]\n",
      "   [ 87  88  89]]]\n",
      "\n",
      "\n",
      " [[[ 90  91  92]\n",
      "   [ 93  94  95]\n",
      "   [ 96  97  98]]\n",
      "\n",
      "  [[ 99 100 101]\n",
      "   [102 103 104]\n",
      "   [105 106 107]]\n",
      "\n",
      "  [[108 109 110]\n",
      "   [111 112 113]\n",
      "   [114 115 116]]\n",
      "\n",
      "  [[117 118 119]\n",
      "   [120 121 122]\n",
      "   [123 124 125]]\n",
      "\n",
      "  [[126 127 128]\n",
      "   [129 130 131]\n",
      "   [132 133 134]]\n",
      "\n",
      "  [[135 136 137]\n",
      "   [138 139 140]\n",
      "   [141 142 143]]\n",
      "\n",
      "  [[144 145 146]\n",
      "   [147 148 149]\n",
      "   [150 151 152]]\n",
      "\n",
      "  [[153 154 155]\n",
      "   [156 157 158]\n",
      "   [159 160 161]]\n",
      "\n",
      "  [[162 163 164]\n",
      "   [165 166 167]\n",
      "   [168 169 170]]\n",
      "\n",
      "  [[171 172 173]\n",
      "   [174 175 176]\n",
      "   [177 178 179]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 49.]],\n",
       "\n",
       "        [[ 58.]],\n",
       "\n",
       "        [[ 67.]],\n",
       "\n",
       "        [[ 76.]],\n",
       "\n",
       "        [[ 85.]],\n",
       "\n",
       "        [[ 94.]],\n",
       "\n",
       "        [[103.]],\n",
       "\n",
       "        [[112.]],\n",
       "\n",
       "        [[121.]],\n",
       "\n",
       "        [[130.]]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(180).reshape(2,10,3,3)\n",
    "print(x)\n",
    "x_bn_mean = np.mean(x, axis=(0, 2, 3), keepdims=True)\n",
    "x_bn_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[17.5]]],\n",
       "\n",
       "\n",
       "       [[[53.5]]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ln_mean = np.mean(x, axis=(1, 2, 3), keepdims=True)\n",
    "x_ln_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 4.]],\n",
       "\n",
       "        [[13.]],\n",
       "\n",
       "        [[22.]],\n",
       "\n",
       "        [[31.]]],\n",
       "\n",
       "\n",
       "       [[[40.]],\n",
       "\n",
       "        [[49.]],\n",
       "\n",
       "        [[58.]],\n",
       "\n",
       "        [[67.]]]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in_mean = np.mean(x, axis=(2, 3), keepdims=True)\n",
    "x_in_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 5, 3, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x.shape[1]\n",
    "x_group = np.reshape(x, (x.shape[0], 2, int(x.shape[1]/2), x.shape[2], x.shape[3]))\n",
    "x_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 1, 1, 1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gn_mean = np.mean(x_group, axis=(2, 3, 4), keepdims=True)\n",
    "x_gn_mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [nn.init.constant_()](https://pytorch.org/docs/stable/nn.init.html)\n",
    ">torch.nn.init.constant_(tensor, val)\n",
    "\n",
    "Fills the input Tensor with the value \\text{val}val ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.3000, 0.3000]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3, 5)\n",
    "nn.init.constant_(w, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.init.normal_()\n",
    ">torch.nn.init.normal_(tensor, mean=0.0, std=1.0)\n",
    "\n",
    "Fills the input Tensor with values drawn from the normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0927, 0.1792, 0.0723, 0.7507, 0.8832],\n",
       "        [0.0970, 0.4864, 0.3152, 0.7508, 0.7109],\n",
       "        [0.6013, 0.3569, 0.1946, 0.9714, 0.7116]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3, 5)\n",
    "nn.init.uniform_(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.functional.pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.pad(input, pad, mode,value ) \n",
    "    \"\"\"\n",
    "    input：四维或者五维的tensor Variabe\n",
    "    pad：不同Tensor的填充方式\n",
    "        1.四维Tensor：传入四元素tuple(pad_l, pad_r, pad_t, pad_b)，\n",
    "        指的是（左填充，右填充，上填充，下填充），其数值代表填充次数\n",
    "        2.六维Tensor：传入六元素tuple(pleft, pright, ptop, pbottom, pfront, pback)，\n",
    "        指的是（左填充，右填充，上填充，下填充，前填充，后填充），其数值代表填充次数\n",
    "    mode： ’constant‘, ‘reflect’ or ‘replicate’三种模式，指的是常量，反射，复制三种模式\n",
    "    value：填充的数值，在\"contant\"模式下默认填充0，mode=\"reflect\" or \"replicate\"时没有默认value参数\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_values:  tensor([[[[ 0.1111, -0.5535],\n",
      "          [-0.3344, -0.5306],\n",
      "          [ 0.2692,  0.3256]]],\n",
      "\n",
      "\n",
      "        [[[-1.4591, -0.0662],\n",
      "          [-0.8564, -0.4760],\n",
      "          [-0.8097,  0.8730]]]]) \n",
      "\n",
      "original_values的shape:  torch.Size([2, 1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "original_values = torch.randn([2,1, 3, 2])\n",
    "print(\"original_values: \",original_values,\"\\n\")\n",
    "print(\"original_values的shape: \",original_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding_values:  tensor([[[[ 0.0000,  0.1111, -0.5535],\n",
      "          [ 0.0000, -0.3344, -0.5306],\n",
      "          [ 0.0000,  0.2692,  0.3256]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -1.4591, -0.0662],\n",
      "          [ 0.0000, -0.8564, -0.4760],\n",
      "          [ 0.0000, -0.8097,  0.8730]]]]) \n",
      "\n",
      "padding_values的shape:  torch.Size([2, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "padding_values = F.pad(original_values, pad=(1,0,0,0), mode=\"constant\", value=0)  \n",
    "print(\"padding_values: \",padding_values,\"\\n\")\n",
    "print(\"padding_values的shape: \",padding_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding_values:  tensor([[[[ 0.1111, -0.5535],\n",
      "          [-0.3344, -0.5306],\n",
      "          [ 0.2692,  0.3256],\n",
      "          [-1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.4591, -0.0662],\n",
      "          [-0.8564, -0.4760],\n",
      "          [-0.8097,  0.8730],\n",
      "          [-1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000]]]]) \n",
      "\n",
      "padding_values的shape:  torch.Size([2, 1, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "padding_values = F.pad(original_values, pad=(0,0,0,3), mode=\"constant\",value=-1)  \n",
    "print(\"padding_values: \",padding_values,\"\\n\")\n",
    "print(\"padding_values的shape: \",padding_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [F.interpolate()](https://pytorch.org/docs/stable/nn.functional.html)\n",
    ">torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None)\n",
    "\n",
    "Down/up samples the input to either the given size or the given scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 8, 10])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.rand((1,2,4,5))\n",
    "src_interp = F.interpolate(src, size=(8, 10),mode='nearest')\n",
    "src_interp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231.23px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
